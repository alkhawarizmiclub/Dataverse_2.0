# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colaboratory.

Envirenmont prep
!pip install numpy pandas matplotlib lightgbm xgboost scikit-learn
"""

# Importing necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import lightgbm as lgb
from xgboost import XGBRegressor

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error, mean_absolute_error


dataset = pd.read_csv('train_dataset.csv')


# Data exploring ===============================================================
print(dataset)

dataset.isna().sum()

for col in dataset:
    print(f"{col} [{len(dataset[col].unique())}] : {dataset[col].unique()}\n")


# Data preprocessing and cleaning ===============================================================
def pre_processing(df, removeNulls: bool = False):

  # One-hot encoding the license status column (It contains only 2 unique values : YES and NO)
  df.replace({"License Status": {"no": 0, "yes": 1}}, inplace=True)

  # One-hot encoding the gearbox column (It contains only 2 unique values : MANUAL and AUTOMATIC)
  df.replace({"Gearbox": {"Manual": 0, "Automatic": 1}}, inplace=True)

  # Label encoding the Manufacturer column
  manufacturer_encoder = LabelEncoder()
  df['Manufacturer'] = manufacturer_encoder.fit_transform(df['Manufacturer'])

  # Label encoding the Body Style column
  manufacturer_encoder = LabelEncoder()
  df['Body Style'] = manufacturer_encoder.fit_transform(df['Body Style'])

  # Label encoding the Powertrain column
  powertrain_encoder = LabelEncoder()
  df['Powertrain'] = manufacturer_encoder.fit_transform(df['Powertrain'])

  # Label encoding the Variant column
  variant_encoder = LabelEncoder()
  df['Variant'] = manufacturer_encoder.fit_transform(df['Variant'])

  # Label encoding the Location column
  location_encoder = LabelEncoder()
  df['Location'] = manufacturer_encoder.fit_transform(df['Location'])

  # Label encoding the Owner_Type column
  owner_encoder = LabelEncoder()
  df['Owner_Type'] = manufacturer_encoder.fit_transform(df['Owner_Type'])

  if removeNulls:
    df = df.dropna()

  return df

dataset = pre_processing(dataset, True)

### Data splitting ....................................
target_name = "Price"

x = dataset.drop(columns=target_name)
y = dataset[target_name]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=52)


# Training ===============================================================

### Linear Regression ....................................
linearRegressor = LinearRegression()
linearRegressor.fit(x_train, y_train)
linearReg_y_pred = linearRegressor.predict(x_test)

### Lasso Regression ....................................
lassoRegressor = Lasso()
lassoRegressor.fit(x_train, y_train)
lassoReg_y_pred = lassoRegressor.predict(x_test)

### LightGBM Regression ....................................
lightGBMRegressor = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=32, n_estimators=200, reg_lambda=1.0)
lightGBMRegressor.fit(x_train, y_train)
lightGBM_y_pred = lightGBMRegressor.predict(x_test)

### XGB Regressor ....................................
xGBRegressor = XGBRegressor()
xGBRegressor.fit(x_train, y_train)
XGB_y_pred = xGBRegressor.predict(x_test)

### Random Forest Regression ....................................
randomForestRegressor = RandomForestRegressor()
randomForestRegressor.fit(x_train, y_train)
randomForest_y_pred = randomForestRegressor.predict(x_test)

### Decision Tree Regressor ....................................
decisionTreeRegressor = DecisionTreeRegressor()
decisionTreeRegressor.fit(x_train, y_train)
decisionTree_y_pred = decisionTreeRegressor.predict(x_test)


# Model comparison ===============================================================

### Comparing the predicted values and the actual values ....................................
figure, axis = plt.subplots(2, 3, figsize=(15, 8))

figure.tight_layout(pad=4.0)
figure.supxlabel('Actual Prices')
figure.supylabel('Predicted Prices')

axis[0, 0].scatter(y_test, linearReg_y_pred)
axis[0, 0].set_title("Linear Regression")

axis[0, 1].scatter(y_test, lassoReg_y_pred)
axis[0, 1].set_title("Lasso Regression")

axis[0, 2].scatter(y_test, lightGBM_y_pred)
axis[0, 2].set_title("LightGBM Regression")

axis[1, 0].scatter(y_test, XGB_y_pred)
axis[1, 0].set_title("XGB Regressor")

axis[1, 1].scatter(y_test, randomForest_y_pred)
axis[1, 1].set_title("Random Forest Regression")

axis[1, 2].scatter(y_test, decisionTree_y_pred)
axis[1, 2].set_title("Decision Tree Regression")


### The error and score of each algorithm ....................................
def addlabels(fig, x,y):
    for i in range(len(x)):
        fig.text(i,y[i],y[i], ha = 'center')

figure, axis = plt.subplots(2, 2, figsize=(16, 10))

figure.tight_layout(pad=4.0)

x_labels = ["linearReg", "lassoReg", "lightGBM", "xGBRegressor", "randomForest", "decisionTree"]

r2_y_values = [linearRegressor.score(x_test, y_test), lassoRegressor.score(x_test, y_test), lightGBMRegressor.score(x_test, y_test), xGBRegressor.score(x_test, y_test), randomForestRegressor.score(x_test, y_test), decisionTreeRegressor.score(x_test, y_test)]
mse_y_valus = [mean_squared_error(y_test, linearReg_y_pred), mean_squared_error(y_test, lassoReg_y_pred), mean_squared_error(y_test, lightGBM_y_pred), mean_squared_error(y_test, XGB_y_pred), mean_squared_error(y_test, randomForest_y_pred), mean_squared_error(y_test, decisionTree_y_pred)]
medianse_y_values = [median_absolute_error(y_test, linearReg_y_pred), median_absolute_error(y_test, lassoReg_y_pred), median_absolute_error(y_test, lightGBM_y_pred), median_absolute_error(y_test, XGB_y_pred), median_absolute_error(y_test, randomForest_y_pred), median_absolute_error(y_test, decisionTree_y_pred)]
mae_y_values = [mean_absolute_error(y_test, linearReg_y_pred), mean_absolute_error(y_test, lassoReg_y_pred), mean_absolute_error(y_test, lightGBM_y_pred), mean_absolute_error(y_test, XGB_y_pred), mean_absolute_error(y_test, randomForest_y_pred), mean_absolute_error(y_test, decisionTree_y_pred)]

axis[0, 0].bar(x_labels, r2_y_values)
axis[0, 0].set_title("R2 Score")
addlabels(axis[0, 0], x_labels, list(map(lambda num: round(num, 6), r2_y_values)))

axis[0, 1].bar(x_labels, mse_y_valus)
axis[0, 1].set_title("Mean Squared Error (MSE)")
addlabels(axis[0, 1], x_labels, list(map(int, mse_y_valus)))

axis[1, 0].bar(x_labels, medianse_y_values)
axis[1, 0].set_title("Median Absolute Error")
addlabels(axis[1, 0], x_labels, list(map(int, medianse_y_values)))

axis[1, 1].bar(x_labels, mae_y_values)
axis[1, 1].set_title("Mean Absolute Error (MAE)")
addlabels(axis[1, 1], x_labels, list(map(int, mae_y_values)))


# Validation ===============================================================

### Saving the submission file ....................................
original_validation_data = pd.read_csv('test_dataset.csv')
validation_data = original_validation_data.set_index('index')

pre_processed_validation_data = pre_processing(validation_data, True)
X_valid = pre_processed_validation_data.values

y_pred_valid = lightGBMRegressor.predict(X_valid)

original_validation_data[target_name] = y_pred_valid
original_validation_data.to_csv('submission_dataset.csv', index=False, encoding='UTF-8')


### Saving the model ....................................
lightGBMRegressor.booster_.save_model('LightGBR_Model.txt')